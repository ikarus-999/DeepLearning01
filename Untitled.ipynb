{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ML\n",
    "--> ** Superviced Learning ==> X:Feature, y:Label(Guide) --------------------- Regression --- [Linear, Logistic, SVM(느림, 옛날),] Artificial NN* (Perceptron==Single Layer NN) \n",
    "                                                                    |\n",
    "                                                                    ---------- Tree(structured Data) -- DecisionTree, *RandomForest(+Bagging), *GBM(+Boost)\n",
    "-->    UnSupervised        ==> X:Feature (NonGuide)  dev++\n",
    "\n",
    "--> Reinforcement ==> AlphaGo X : Zero\n",
    "\n",
    "취업하려면 : 논문을 TF PyT 구현할 수 있는정도면 됨 / 리서치 : 연구경력++"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "m -> # of data\n",
    "x -> feature\n",
    "y -> label\n",
    "w -> weight\n",
    "b -> bias\n",
    "\n",
    "1-Layer NN ( == Perceptron)\n",
    "\n",
    "   w1\n",
    "x1 -> E -> y_predict\n",
    "x2 ->\n",
    "x3 ->\n",
    "xN\n",
    "\n",
    "\n",
    "\n",
    "x 여러개 :: w 여러개\n",
    "\n",
    "h(x) -> w * x Hypothesis Function(y-predict)\n",
    "\n",
    "\n",
    "L(h(x),y) = Loss Function : 좋을수록 0, 안좋을수록 무한대 --> 미분가능한 Loss Func 얼마나 많이 w를 업데이트? 완만하면 조금\n",
    " = 1/2 * (h(x) - y)^2 <MSE LOSS>\n",
    "    \n",
    "    \n",
    "\n",
    "J(w, b) = Cost Function : 데이터가 여러개 가정 \n",
    "1/m * sigma i:1~m L(h(x)^i, y^i)\n",
    "\n",
    "\n",
    "L(h(x),y)\n",
    "|\n",
    "|\n",
    "|\n",
    "------------ w\n",
    "\n",
    "얼마나 업데이트를 하는지\n",
    "기울기 차이없으면 정답근접\n",
    "\n",
    "미분 : 순간변화율 Lim4x->0 f(x+4x)-f(x) / 4x\n",
    "\n",
    "\n",
    "L(hx,y) -> 9w :: w = w - 9/9w J(w)\n",
    "\n",
    "합성함수의 미분\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100,)\n",
      "(100,)\n",
      "[0.0056182  0.35214625 0.11237319 0.08519306 0.24205322]\n",
      "[0.68043531 0.49670057 0.56695943 0.59879911 0.15229833]\n"
     ]
    }
   ],
   "source": [
    "x1 = np.random.uniform(low=0.0, high=1.0, size=100)\n",
    "x2 = np.random.uniform(low=0.0, high=1.0, size=100)\n",
    "\n",
    "print(x1.shape)\n",
    "print(x2.shape)\n",
    "\n",
    "print(x1[0:5])\n",
    "print(x2[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.44190311, 0.45399416, 0.41719167, 0.42495747, 0.24876513])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = 0.3 * x1 + 0.5 * x2 + 0.1 ##bias 절편\n",
    "\n",
    "\n",
    "\n",
    "print(y.shape)\n",
    "y[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "y = 0.3 * x 0.3 --> weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      0 w1 = 0.933814 w2 = 0.561370 b = 0.513631 error = 0.922551\n",
      "      1 w1 = 0.016976 w2 = 0.882946 b = 0.363049 error = 0.490450\n",
      "      3 w1 = 0.666132 w2 = 0.782422 b = 0.046005 error = 0.468968\n",
      "      8 w1 = 0.837663 w2 = 0.572344 b = 0.013051 error = 0.414593\n",
      "      9 w1 = 0.002323 w2 = 0.422297 b = 0.402986 error = 0.264478\n",
      "     12 w1 = 0.149430 w2 = 0.593490 b = 0.111811 error = 0.211623\n",
      "     16 w1 = 0.439146 w2 = 0.303192 b = 0.143211 error = 0.199458\n",
      "     20 w1 = 0.202967 w2 = 0.357258 b = 0.096822 error = 0.153697\n",
      "     37 w1 = 0.296589 w2 = 0.208006 b = 0.190057 error = 0.148044\n",
      "    139 w1 = 0.082147 w2 = 0.255750 b = 0.182098 error = 0.142624\n",
      "    165 w1 = 0.124043 w2 = 0.109300 b = 0.342533 error = 0.129957\n",
      "    603 w1 = 0.087567 w2 = 0.195176 b = 0.276685 error = 0.127976\n",
      "   2045 w1 = 0.011872 w2 = 0.081378 b = 0.362536 error = 0.121717\n",
      "  26367 w1 = 0.061942 w2 = 0.031417 b = 0.390530 error = 0.121641\n",
      "  36017 w1 = 0.052159 w2 = 0.045197 b = 0.382447 error = 0.121223\n",
      "  45125 w1 = 0.036155 w2 = 0.051936 b = 0.374456 error = 0.120964\n",
      " 212108 w1 = 0.004933 w2 = 0.021129 b = 0.399881 error = 0.120961\n",
      " 328445 w1 = 0.014467 w2 = 0.038838 b = 0.388927 error = 0.120932\n",
      " 343784 w1 = 0.020256 w2 = 0.017782 b = 0.397236 error = 0.120917\n",
      " 358021 w1 = 0.022620 w2 = 0.021123 b = 0.395263 error = 0.120905\n",
      " 675304 w1 = 0.032291 w2 = 0.023052 b = 0.393568 error = 0.120869\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      " 675304 w1 = 0.032291 w2 = 0.023052 b = 0.393568 error = 0.120869\n"
     ]
    }
   ],
   "source": [
    "num_epoch = 1000000\n",
    "\n",
    "best_error = np.Infinity\n",
    "best_epoch = None\n",
    "best_w1 = None\n",
    "best_w2 = None\n",
    "best_b = None\n",
    "\n",
    "for epoch in range(num_epoch):\n",
    "    w1 = np.random.uniform(low=0.0, high=1.0)\n",
    "    w2 = np.random.uniform(low=0.0, high=1.0)\n",
    "    b =  np.random.uniform(low=0.0, high=1.0)\n",
    "    \n",
    "    y_predict = w1 * x1 + w2 * x2 + b\n",
    "    \n",
    "    error = np.abs(y_predict - y).mean()\n",
    "    \n",
    "    if error < best_error:\n",
    "        best_error = error\n",
    "        best_epoch= epoch\n",
    "        best_w1 = w1\n",
    "        best_w2 = w2\n",
    "        best_b = b\n",
    "        \n",
    "        print(f\"{best_epoch:7} w1 = {best_w1:.6f} w2 = {best_w2:.6f} b = {best_b:.6f} error = {best_error:.6f}\")\n",
    "print(\"-----------\" * 10)\n",
    "print(f\"{best_epoch:7} w1 = {best_w1:.6f} w2 = {best_w2:.6f} b = {best_b:.6f} error = {best_error:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### H-step Search : Gradient Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0 w = 0.586946 error = 0.142180\n",
      " 1 w = 0.576946 error = 0.137225\n",
      " 2 w = 0.566946 error = 0.132270\n",
      " 3 w = 0.556946 error = 0.127315\n",
      " 4 w = 0.546946 error = 0.122360\n",
      " 5 w = 0.536946 error = 0.117405\n",
      " 6 w = 0.526946 error = 0.112450\n",
      " 7 w = 0.516946 error = 0.107496\n",
      " 8 w = 0.506946 error = 0.102541\n",
      " 9 w = 0.496946 error = 0.097586\n",
      "10 w = 0.486946 error = 0.092631\n",
      "11 w = 0.476946 error = 0.087676\n",
      "12 w = 0.466946 error = 0.082721\n",
      "13 w = 0.456946 error = 0.077766\n",
      "14 w = 0.446946 error = 0.072811\n",
      "15 w = 0.436946 error = 0.067856\n",
      "16 w = 0.426946 error = 0.062901\n",
      "17 w = 0.416946 error = 0.057946\n",
      "18 w = 0.406946 error = 0.052991\n",
      "19 w = 0.396946 error = 0.048036\n",
      "20 w = 0.386946 error = 0.043081\n",
      "21 w = 0.376946 error = 0.038126\n",
      "22 w = 0.366946 error = 0.033172\n",
      "23 w = 0.356946 error = 0.028217\n",
      "24 w = 0.346946 error = 0.023262\n",
      "25 w = 0.336946 error = 0.018307\n",
      "26 w = 0.326946 error = 0.013352\n",
      "27 w = 0.316946 error = 0.008397\n",
      "28 w = 0.306946 error = 0.003442\n",
      "29 w = 0.296946 error = 0.001513\n",
      "--------------------------------------------------\n",
      "30 w = 0.296946 error = 0.001513\n"
     ]
    }
   ],
   "source": [
    "num_epoch = 100\n",
    "h = 0.01\n",
    "w = np.random.uniform(low=0.0, high=1.0)\n",
    "\n",
    "for epoch in range(num_epoch):\n",
    "    y_predict = w * x\n",
    "    current_error = np.abs(y_predict - y).mean()\n",
    "    \n",
    "    y_predict = (w + h)*x\n",
    "    h_plus_error = np.abs(y_predict- y).mean()\n",
    "    if h_plus_error < current_error:\n",
    "        w = w + h\n",
    "        print(f\"{epoch:2} w = {w:.6f} error = {h_plus_error:.6f}\")\n",
    "        continue\n",
    "        \n",
    "    y_predict = (w - h)*x\n",
    "    h_minus_error = np.abs(y_predict- y).mean()\n",
    "    if h_minus_error < current_error:\n",
    "        w = w - h\n",
    "        print(f\"{epoch:2} w = {w:.6f} error = {h_minus_error:.6f}\")\n",
    "        continue\n",
    "    break\n",
    "    \n",
    "print(\"-----\" * 10)\n",
    "print(f\"{epoch:2} w = {w:.6f} error = {current_error:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Descent(not Yet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   0 w1 = 0.236925 w2 = 0.394974 b = -0.354106 error = 0.904341\n",
      "   1 w1 = 0.541567 w2 = 0.676289 b = 0.187648 error = 0.541753\n",
      "   2 w1 = 0.351526 w2 = 0.505573 b = -0.122305 error = 0.309952\n",
      "   3 w1 = 0.453260 w2 = 0.601143 b = 0.068654 error = 0.190959\n",
      "   4 w1 = 0.383788 w2 = 0.540159 b = -0.035669 error = 0.104323\n",
      "   5 w1 = 0.415612 w2 = 0.571520 b = 0.033424 error = 0.069093\n",
      "   6 w1 = 0.388295 w2 = 0.548707 b = 0.000055 error = 0.042012\n",
      "   7 w1 = 0.396252 w2 = 0.557962 b = 0.026637 error = 0.031457\n",
      "   8 w1 = 0.383878 w2 = 0.548514 b = 0.017585 error = 0.027086\n",
      "   9 w1 = 0.383882 w2 = 0.550245 b = 0.029181 error = 0.023721\n",
      "  10 w1 = 0.376986 w2 = 0.545558 b = 0.028311 error = 0.022674\n",
      "  11 w1 = 0.374517 w2 = 0.544807 b = 0.034483 error = 0.021044\n",
      "  12 w1 = 0.369788 w2 = 0.541891 b = 0.036229 error = 0.020149\n",
      "  13 w1 = 0.366715 w2 = 0.540396 b = 0.040312 error = 0.018995\n",
      "  14 w1 = 0.362976 w2 = 0.538206 b = 0.042765 error = 0.018105\n",
      "  15 w1 = 0.359920 w2 = 0.536561 b = 0.045936 error = 0.017149\n",
      "  16 w1 = 0.356738 w2 = 0.534726 b = 0.048454 error = 0.016310\n",
      "  17 w1 = 0.353891 w2 = 0.533129 b = 0.051138 error = 0.015474\n",
      "  18 w1 = 0.351093 w2 = 0.531513 b = 0.053517 error = 0.014703\n",
      "  19 w1 = 0.348500 w2 = 0.530024 b = 0.055878 error = 0.013958\n",
      "  20 w1 = 0.346007 w2 = 0.528572 b = 0.058062 error = 0.013258\n",
      "  21 w1 = 0.343664 w2 = 0.527205 b = 0.060172 error = 0.012589\n",
      "  22 w1 = 0.341431 w2 = 0.525890 b = 0.062156 error = 0.011956\n",
      "  23 w1 = 0.339320 w2 = 0.524642 b = 0.064053 error = 0.011354\n",
      "  24 w1 = 0.337314 w2 = 0.523449 b = 0.065849 error = 0.010783\n",
      "  25 w1 = 0.335415 w2 = 0.522314 b = 0.067559 error = 0.010240\n",
      "  26 w1 = 0.333612 w2 = 0.521231 b = 0.069181 error = 0.009725\n",
      "  27 w1 = 0.331902 w2 = 0.520199 b = 0.070723 error = 0.009236\n",
      "  28 w1 = 0.330281 w2 = 0.519216 b = 0.072188 error = 0.008772\n",
      "  29 w1 = 0.328743 w2 = 0.518280 b = 0.073580 error = 0.008331\n",
      "  30 w1 = 0.327283 w2 = 0.517387 b = 0.074902 error = 0.007912\n",
      "  31 w1 = 0.325899 w2 = 0.516538 b = 0.076158 error = 0.007514\n",
      "  32 w1 = 0.324585 w2 = 0.515729 b = 0.077352 error = 0.007137\n",
      "  33 w1 = 0.323339 w2 = 0.514958 b = 0.078485 error = 0.006778\n",
      "  34 w1 = 0.322157 w2 = 0.514225 b = 0.079562 error = 0.006438\n",
      "  35 w1 = 0.321035 w2 = 0.513527 b = 0.080586 error = 0.006114\n",
      "  36 w1 = 0.319970 w2 = 0.512862 b = 0.081558 error = 0.005807\n",
      "  37 w1 = 0.318960 w2 = 0.512229 b = 0.082481 error = 0.005515\n",
      "  38 w1 = 0.318001 w2 = 0.511627 b = 0.083358 error = 0.005238\n",
      "------------------------------------------------------------\n",
      "  39 w1 = 0.318001 w2 = 0.511627  b = 0.083358 error = 0.004975\n"
     ]
    }
   ],
   "source": [
    "num_epoch = 100\n",
    "learning_rate = 1.0\n",
    "##error = np.Infinity\n",
    "\n",
    "w1 = np.random.uniform(low=0.0, high=1.0)\n",
    "w2 = np.random.uniform(low=0.0, high=1.0)\n",
    "b = np.random.uniform(low=0.0, high=1.0)\n",
    "\n",
    "for epoch in range(num_epoch):\n",
    "    y_predict = w1 * x1 + w2 * x2 + b\n",
    "    \n",
    "    error = np.abs(y_predict - y).mean()\n",
    "    \n",
    "    if error < 0.005:   ##np.amax(y_predict - y):\n",
    "       break\n",
    "    \n",
    "    w1 = w1 - learning_rate * ((y_predict - y) * x1).mean()\n",
    "    w2 = w2 -learning_rate * ((y_predict - y) * x2).mean()\n",
    "    b = b - learning_rate * (y_predict - y).mean()\n",
    "    \n",
    "    print(f\"{epoch:4} w1 = {w1:.6f} w2 = {w2:.6f} b = {b:.6f} error = {error:.6f}\")\n",
    "    \n",
    "print(\"------\"*10)\n",
    "print(f\"{epoch:4} w1 = {w1:.6f} w2 = {w2:.6f}  b = {b:.6f} error = {error:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
